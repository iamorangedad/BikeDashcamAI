"""
SigLIP æ¨¡å‹å¯¼å‡ºä¸º TensorRT å¼•æ“
"""

import torch
from transformers import SiglipModel, SiglipProcessor
import tensorrt as trt
import numpy as np


def export_siglip_to_onnx(output_path: str = "siglip.onnx"):
    """
    å¯¼å‡º SigLIP åˆ° ONNX æ ¼å¼

    Args:
        output_path: è¾“å‡º ONNX æ–‡ä»¶è·¯å¾„
    """
    print("ğŸ“¦ åŠ è½½ SigLIP æ¨¡å‹...")
    model = SiglipModel.from_pretrained("google/siglip-base-patch16-224")
    model.eval()

    processor = SiglipProcessor.from_pretrained("google/siglip-base-patch16-224")

    # å‡†å¤‡ç¤ºä¾‹è¾“å…¥
    dummy_image = torch.randn(1, 3, 224, 224)

    print(f"ğŸš€ å¯¼å‡º SigLIP åˆ° {output_path}...")

    torch.onnx.export(
        model,
        dummy_image,
        output_path,
        input_names=["pixel_values"],
        output_names=["image_features"],
        dynamic_axes={
            "pixel_values": {0: "batch_size"},
            "image_features": {0: "batch_size"},
        },
        opset_version=17,
    )

    print(f"âœ… SigLIP å·²å¯¼å‡ºåˆ° {output_path}")
    return output_path


def convert_onnx_to_tensorrt(
    onnx_path: str, engine_path: str = "siglip.plan", fp16_mode: bool = True
):
    """
    å°† ONNX æ¨¡å‹è½¬æ¢ä¸º TensorRT å¼•æ“

    Args:
        onnx_path: ONNX æ¨¡å‹è·¯å¾„
        engine_path: è¾“å‡º TensorRT å¼•æ“è·¯å¾„
        fp16_mode: æ˜¯å¦ä½¿ç”¨ FP16 ç²¾åº¦
    """
    TRT_LOGGER = trt.Logger(trt.Logger.INFO)

    print("ğŸ”§ åˆå§‹åŒ– TensorRT...")
    builder = trt.Builder(TRT_LOGGER)
    network = builder.create_network(
        1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)
    )
    parser = trt.OnnxParser(network, TRT_LOGGER)

    print(f"ğŸ“– è¯»å– ONNX æ¨¡å‹: {onnx_path}")
    with open(onnx_path, "rb") as model:
        if not parser.parse(model.read()):
            print("âŒ ONNX è§£æå¤±è´¥:")
            for error in range(parser.num_errors):
                print(parser.get_error(error))
            return

    print("âœ… ONNX æ¨¡å‹è§£ææˆåŠŸ")

    # é…ç½® TensorRT
    config = builder.create_builder_config()

    if fp16_mode and builder.platform_has_fast_fp16:
        config.set_flag(trt.BuilderFlag.FP16)
        print("âš¡ å¯ç”¨ FP16 æ¨¡å¼")

    # è®¾ç½®æœ€å¤§å·¥ä½œç©ºé—´
    config.max_workspace_size = 1 << 30  # 1GB

    print("ğŸ”¨ æ„å»º TensorRT å¼•æ“...")
    serialized_engine = builder.build_serialized_network(network, config)

    if not serialized_engine:
        print("âŒ TensorRT å¼•æ“æ„å»ºå¤±è´¥")
        return

    print(f"ğŸ’¾ ä¿å­˜ TensorRT å¼•æ“åˆ° {engine_path}")
    with open(engine_path, "wb") as f:
        f.write(serialized_engine)

    print("âœ… TensorRT å¼•æ“æ„å»ºå®Œæˆ")
    return engine_path


def test_inference(engine_path: str, input_image: np.ndarray):
    """
    æµ‹è¯• TensorRT æ¨ç†

    Args:
        engine_path: TensorRT å¼•æ“è·¯å¾„
        input_image: è¾“å…¥å›¾åƒæ•°ç»„ (1, 3, 224, 224)
    """
    print(f"ğŸ§ª æµ‹è¯•æ¨ç†: {engine_path}")

    TRT_LOGGER = trt.Logger(trt.Logger.INFO)

    # åŠ è½½å¼•æ“
    with open(engine_path, "rb") as f:
        engine = trt.Runtime(TRT_LOGGER).deserialize_cuda_engine(f.read())

    # åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
    context = engine.create_execution_context()

    # å‡†å¤‡è¾“å…¥è¾“å‡ºç¼“å†²åŒº
    inputs = [input_image]
    outputs = []
    bindings = []

    for i in range(engine.num_io_tensors):
        name = engine.get_tensor_name(i)
        dtype = trt.nptype(engine.get_tensor_dtype(name))
        shape = context.get_tensor_shape(name)

        if engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:
            bindings.append(inputs[i].astype(dtype).reshape(shape))
        else:
            output = np.empty(shape, dtype=dtype)
            outputs.append(output)
            bindings.append(output)

    # æ‰§è¡Œæ¨ç†
    print("ğŸš€ æ‰§è¡Œæ¨ç†...")
    for i in range(engine.num_io_tensors):
        context.set_tensor_address(engine.get_tensor_name(i), bindings[i].ctypes.data)

    context.execute_async_v3(0)

    print(f"âœ… æ¨ç†å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {outputs[0].shape}")
    return outputs[0]


if __name__ == "__main__":
    # å¯¼å‡ºåˆ° ONNX
    onnx_path = export_siglip_to_onnx()

    # è½¬æ¢ä¸º TensorRT
    engine_path = convert_onnx_to_tensorrt(onnx_path)

    # æµ‹è¯•æ¨ç†
    dummy_input = np.random.randn(1, 3, 224, 224).astype(np.float32)
    test_inference(engine_path, dummy_input)
